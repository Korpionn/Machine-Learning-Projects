{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7599a87d-bf23-425b-a3ca-5b0dfd8a66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d68281-12b2-4709-813d-5d3ef6035c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app =  Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a078d2-c8f0-42db-8c15-4ff5b7c2a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = joblib.load('rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5110e225-d615-4d32-9f1c-0672a68967d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamran\\anaconda3\\anaconda_new\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# define a route for making predictions\n",
    "@app.route('/predict', methods = ['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    input_data = np.array(data['input']).reshape(1 , -1)\n",
    "    predictions = model.predict(input_data)\n",
    "    return jsonify({'prediction': int(predictions[0])})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b17f6-4bdb-4a2d-8998-adbad4c05dbe",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "So, this is how we can package Machine Learning models in the form of APIs. Model packaging is an essential step in the machine learning deployment process, where the trained model is prepared in a format that can be easily deployed and integrated into production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc950e-78c1-4907-9868-eb3e99e89a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
